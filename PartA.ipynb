{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PartA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvATUn+IkpT0PJTJ2r5MMJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swetha-rana/Assignment-2/blob/main/PartA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "url = 'https://storage.googleapis.com/wandb_datasets/nature_12K.zip'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('nature_12K.zip', 'wb').write(r.content)\n",
        "!wget 'https://storage.googleapis.com/wandb_datasets/nature_12K.zip'\n",
        "!unzip nature_12K.zip"
      ],
      "metadata": {
        "id": "IIIMqcs8ig8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "ef7Rbl4eigo4"
      },
      "execution_count": null,
      "outputs": []
    },

    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0MyKIgFidb-"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.init(project=\"CS6910_Assignment2\", entity=\"swe-rana\")\n",
        "from wandb.keras import WandbCallback"
      ]
    },


    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten,BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from tensorflow.keras.metrics import categorical_crossentropy\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def data(image_size,augment_data,batch_size):\n",
        "      home_path = \"/content/inaturalist_12K\"\n",
        "      train_path = os.path.join(home_path,'train')\n",
        "      test_path = os.path.join(home_path,'val')\n",
        "      if augment_data == True:\n",
        "        train_data = ImageDataGenerator(rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True,brightness_range=[0.2,1.2],validation_split=0.1) # brightness\n",
        "        test_data = ImageDataGenerator(rotation_range=10, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True,brightness_range=[0.2,1.2]) # brightness\n",
        "\n",
        "      else:\n",
        "        train_data = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "        test_data = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "      train_generator = train_data.flow_from_directory(directory= train_path,target_size=(image_size, image_size), batch_size=batch_size,color_mode=\"rgb\",class_mode=\"categorical\",subset = \"training\")\n",
        "      val_generator = train_data.flow_from_directory(directory= train_path,target_size=(image_size, image_size), batch_size=batch_size,color_mode=\"rgb\",class_mode=\"categorical\",subset = \"validation\")\n",
        "      test_generator = test_data.flow_from_directory(directory= test_path,target_size=(image_size, image_size), batch_size=batch_size,color_mode=\"rgb\",class_mode=\"categorical\")\n",
        "      return train_generator,val_generator,test_generator\n",
        "\n",
        "def CNN_model(image_size,kernel_size,num_filters,filter_org,dropout,batch_norm,epochs,dense_size,lr):\n",
        "            if filter_org == \"same\":\n",
        "                filters = [num_filters,num_filters,num_filters,num_filters,num_filters]\n",
        "            if filter_org == \"doubling\":\n",
        "                filters = [num_filters,num_filters*2,num_filters*4,num_filters*8,num_filters*16]\n",
        "            if filter_org == \"halving\":\n",
        "                filters = [num_filters,int(num_filters/2),int(num_filters/4),int(num_filters/8),int(num_filters/16)]\n",
        "\n",
        "            nature_model = Sequential()\n",
        "            nature_model.add(Conv2D(filters[0], kernel_size=(kernel_size, kernel_size),activation='relu',input_shape=(image_size,image_size,3)))\n",
        "            if batch_norm == True:\n",
        "                          print(\"batch_norm\")\n",
        "                          nature_model.add(BatchNormalization())\n",
        "            nature_model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "            nature_model.add(Conv2D(filters[1], kernel_size=(kernel_size, kernel_size),activation='relu',input_shape=(image_size,image_size,3)))\n",
        "            if batch_norm == True:\n",
        "                          nature_model.add(BatchNormalization())\n",
        "            nature_model.add(MaxPooling2D(2, 2)) \n",
        "            nature_model.add(BatchNormalization())\n",
        "\n",
        "            nature_model.add(Conv2D(filters[2], kernel_size=(kernel_size, kernel_size),activation='relu',input_shape=(image_size,image_size,3)))\n",
        "            if batch_norm == True:\n",
        "                          nature_model.add(BatchNormalization())\n",
        "            nature_model.add(MaxPooling2D(2, 2))  \n",
        "\n",
        "            nature_model.add(Conv2D(filters[3], kernel_size=(kernel_size, kernel_size),activation='relu',input_shape=(image_size,image_size,3)))\n",
        "            if batch_norm == True:\n",
        "                          nature_model.add(BatchNormalization())\n",
        "            nature_model.add(MaxPooling2D(2, 2)) \n",
        "\n",
        "            nature_model.add(Conv2D(filters[4], kernel_size=(kernel_size, kernel_size),activation='relu',input_shape=(image_size,image_size,3)))\n",
        "            if batch_norm == True:\n",
        "                          nature_model.add(BatchNormalization())\n",
        "            nature_model.add(MaxPooling2D(2, 2))             \n",
        "            nature_model.add(Flatten())\n",
        "            nature_model.add(Dense(dense_size, activation='relu'))\n",
        "            nature_model.add(Dropout(dropout))\n",
        "\n",
        "            \n",
        "            nature_model.add(Dense(10, activation='softmax'))\n",
        "            return nature_model\n",
        "\n",
        "#hist = nature_model.fit(train_generator,epochs=2,validation_data=val_generator)\n",
        "#nature_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#nature_train = nature_model.fit(x = train_generator, validation_data = val_generator, epochs = 2)\n",
        "\n"
      ],
      "metadata": {
        "id": "OY1NugtXimGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setRunName(image_size,kernel_size,num_filters, filter_org, augment_data, dropout,batch_size,dense_size, batch_norm):\n",
        "    \n",
        "    augment_data_options = {True: \"Y\", False: \"N\"}\n",
        "    batch_norm_options = {True: \"Y\", False: \"N\"}\n",
        "\n",
        "    run_name = \"_\".join([\"img\",str(image_size),\"ker\",str(kernel_size),\"num\", str(num_filters), \"org\", str(filter_org), \"aug\", augment_data_options[augment_data],\n",
        "                      \"drop\", str(dropout), \"bat\",str(batch_size),\"den\",str(dense_size),\"norm\", batch_norm_options[batch_norm]])\n",
        "    \n",
        "    return run_name\n"
      ],
      "metadata": {
        "id": "gOn6ncIEipnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def train():\n",
        "\n",
        "        config_defaults = {\n",
        "            \"image_size\" :200,\n",
        "            \"kernel_size\" : 5,\n",
        "            \"num_filters\": 32,\n",
        "            \"filter_org\": \"same\",\n",
        "            \"augment_data\": False,\n",
        "            \"dropout\": 0.3,\n",
        "            \"batch_norm\": False,\n",
        "            \"epochs\": 10,\n",
        "            \"batch_size\" : 256,\n",
        "            \"dense_size\": 64,\n",
        "            \"lr\": 0.001\n",
        "        }\n",
        "\n",
        "        wandb.init(config=config_defaults)\n",
        "        config = wandb.config\n",
        "        wandb.run.name = setRunName(config.image_size,config.kernel_size,config.num_filters, config.filter_org, config.augment_data, config.dropout,config.batch_size,config.dense_size, config.batch_norm)\n",
        "       \n",
        "        train_gen, val_gen, test_gen = data(image_size=config.image_size,augment_data=config.augment_data,batch_size=config.batch_size)\n",
        "        model = CNN_model(image_size=config.image_size,kernel_size=config.kernel_size,num_filters=config.num_filters, filter_org=config.filter_org,dropout=config.dropout, batch_norm=config.batch_norm,epochs=config.epochs,dense_size=config.dense_size,lr=config.lr)\n",
        "        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=\"categorical_accuracy\")\n",
        "        model.fit(train_gen, epochs=config.epochs, validation_data=val_gen, callbacks=[WandbCallback()])\n",
        "        model.summary()\n"
      ],
      "metadata": {
        "id": "qqwDw418isDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up a sweep config\n",
        "sweep_config = {\n",
        "    \"name\": \"Assignment_2_partA_all_params\",\n",
        "    \"description\": \"Assignment_2_partA_all_params\",\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\" : {\n",
        "        \"name\" : \"val_categorical_accuracy\",\n",
        "        \"goal\" : \"maximize\"\n",
        "    },\n",
        "    \"project\": \"CS6910_Assignment2\",\n",
        "    \"parameters\": {\n",
        "        \"num_filters\": {\n",
        "            \"values\": [32,64]\n",
        "        },\n",
        "        \"filter_org\": {\n",
        "            \"values\": [\"same\",\"doubling\",\"halving\"]\n",
        "        },\n",
        "        \"augment_data\": {\n",
        "            \"values\": [True,False]\n",
        "        },\n",
        "        \"kernel_size\" : {\n",
        "            \"values\" : [3,4,5]\n",
        "        },\n",
        "        \"image_size\" : {\n",
        "            \"values\" :[200,256,512]\n",
        "        },\n",
        "        \"batch_size\":{\n",
        "            \"values\":[200,256,400]\n",
        "        },\n",
        "        \"dropout\": {\n",
        "            \"values\": [0.2,0.3]\n",
        "        },\n",
        "        \"batch_norm\": {\n",
        "            \"values\": [True,False]\n",
        "        },\n",
        "        \"dense_size\": {\n",
        "            \"values\": [32,64]\n",
        "        },\n",
        "        \"lr\": {\n",
        "            \"values\": [0.001]\n",
        "        },\n",
        "        \"epochs\": {\n",
        "            \"values\": [10]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# creating the sweep\n"
      ],
      "metadata": {
        "id": "IR7ObiP5iu8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wandb.agent(sweep_id, function=train)\n",
        "sweep_id = \"p2xljnch\"\n",
        "wandb.agent(sweep_id,train,entity=\"swe-rana\",project=\"CS6910_Assignment2\")"
      ],
      "metadata": {
        "id": "3HbSo4UOiyJw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}

